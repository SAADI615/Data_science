{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c21566-0ca9-4f89-90c5-762524739220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34d7a02-6354-442a-8fe6-eaddbfe1deae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSA1</th>\n",
       "      <th>LSA2</th>\n",
       "      <th>LSA3</th>\n",
       "      <th>LSA4</th>\n",
       "      <th>LSA5</th>\n",
       "      <th>LSA6</th>\n",
       "      <th>LSA7</th>\n",
       "      <th>LSA8</th>\n",
       "      <th>LSA9</th>\n",
       "      <th>LSA10</th>\n",
       "      <th>...</th>\n",
       "      <th>FASTTEXT248</th>\n",
       "      <th>FASTTEXT249</th>\n",
       "      <th>FASTTEXT250</th>\n",
       "      <th>FASTTEXT251</th>\n",
       "      <th>FASTTEXT252</th>\n",
       "      <th>FASTTEXT253</th>\n",
       "      <th>FASTTEXT254</th>\n",
       "      <th>FASTTEXT255</th>\n",
       "      <th>FASTTEXT256</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396314</td>\n",
       "      <td>-0.036150</td>\n",
       "      <td>0.064518</td>\n",
       "      <td>-0.073159</td>\n",
       "      <td>0.096052</td>\n",
       "      <td>-0.050067</td>\n",
       "      <td>-0.090869</td>\n",
       "      <td>0.037282</td>\n",
       "      <td>0.100209</td>\n",
       "      <td>0.046334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.401282</td>\n",
       "      <td>-0.186660</td>\n",
       "      <td>-0.115922</td>\n",
       "      <td>-0.267420</td>\n",
       "      <td>-0.016475</td>\n",
       "      <td>-0.064113</td>\n",
       "      <td>-0.072102</td>\n",
       "      <td>-0.035793</td>\n",
       "      <td>0.172962</td>\n",
       "      <td>-0.108011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.421012</td>\n",
       "      <td>-0.051170</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>-0.184141</td>\n",
       "      <td>-0.075076</td>\n",
       "      <td>-0.184510</td>\n",
       "      <td>-0.078020</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>-0.018534</td>\n",
       "      <td>0.067499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.419083</td>\n",
       "      <td>0.137935</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>0.027398</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>0.017428</td>\n",
       "      <td>-0.058439</td>\n",
       "      <td>-0.094601</td>\n",
       "      <td>0.061460</td>\n",
       "      <td>-0.050057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000160</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000250</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.411648</td>\n",
       "      <td>0.156481</td>\n",
       "      <td>0.054695</td>\n",
       "      <td>-0.188321</td>\n",
       "      <td>0.130529</td>\n",
       "      <td>-0.111796</td>\n",
       "      <td>0.059512</td>\n",
       "      <td>-0.038671</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>-0.163627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 929 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LSA1      LSA2      LSA3      LSA4      LSA5      LSA6      LSA7  \\\n",
       "0  0.396314 -0.036150  0.064518 -0.073159  0.096052 -0.050067 -0.090869   \n",
       "1  0.401282 -0.186660 -0.115922 -0.267420 -0.016475 -0.064113 -0.072102   \n",
       "2  0.421012 -0.051170  0.031429 -0.184141 -0.075076 -0.184510 -0.078020   \n",
       "3  0.419083  0.137935  0.029789  0.027398  0.053296  0.017428 -0.058439   \n",
       "4  0.411648  0.156481  0.054695 -0.188321  0.130529 -0.111796  0.059512   \n",
       "\n",
       "       LSA8      LSA9     LSA10  ...  FASTTEXT248  FASTTEXT249  FASTTEXT250  \\\n",
       "0  0.037282  0.100209  0.046334  ...    -0.000002     0.000001     0.000263   \n",
       "1 -0.035793  0.172962 -0.108011  ...    -0.000108     0.000068     0.000095   \n",
       "2  0.011355 -0.018534  0.067499  ...     0.000265     0.000006     0.000012   \n",
       "3 -0.094601  0.061460 -0.050057  ...    -0.000055     0.000263    -0.000010   \n",
       "4 -0.038671  0.045371 -0.163627  ...    -0.000156     0.000129    -0.000020   \n",
       "\n",
       "   FASTTEXT251  FASTTEXT252  FASTTEXT253  FASTTEXT254  FASTTEXT255  \\\n",
       "0     0.000348    -0.000052    -0.000270    -0.000334     0.000353   \n",
       "1    -0.000318     0.000315     0.000111    -0.000155     0.000010   \n",
       "2    -0.000199     0.000148     0.000175    -0.000399     0.000139   \n",
       "3    -0.000090    -0.000160    -0.000041    -0.000250     0.000085   \n",
       "4     0.000163     0.000375     0.000178    -0.000314    -0.000084   \n",
       "\n",
       "   FASTTEXT256  TARGET  \n",
       "0     0.000310       0  \n",
       "1     0.000061       0  \n",
       "2    -0.000191       0  \n",
       "3    -0.000165       0  \n",
       "4    -0.000133       0  \n",
       "\n",
       "[5 rows x 929 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnull = pd.read_csv('TOP_FEATURES2.csv')\n",
    "dfnull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce4b7a9-f40e-43ef-8a6f-d3c974114beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 929)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdcf828f-ede9-4ab6-85cf-3102b8c4cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfnull.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4975fa7-36aa-4087-8c3d-3faaad433998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSA1           0\n",
       "LSA2           0\n",
       "LSA3           0\n",
       "LSA4           0\n",
       "LSA5           0\n",
       "              ..\n",
       "FASTTEXT253    0\n",
       "FASTTEXT254    0\n",
       "FASTTEXT255    0\n",
       "FASTTEXT256    0\n",
       "TARGET         0\n",
       "Length: 929, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2195c48a-3cb5-47f5-b224-0e9edb00c36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"TARGET\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fed8d1-08fd-42c9-a6cf-4a461037e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"TARGET\"]\n",
    "x = df.drop(\"TARGET\", axis=1) \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e873a61b-7f9c-410e-a9de-a2a9ad503a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Classifier  Accuracy       mcc  \\\n",
      "0  RandomForestClassifier(max_depth=10, n_estimat...  0.827074  0.674285   \n",
      "1  XGBClassifier(base_score=None, booster=None, c...  0.876369  0.753270   \n",
      "2      LGBMClassifier(max_depth=10, random_state=50)  0.885759  0.775667   \n",
      "3  GradientBoostingClassifier(learning_rate=0.5, ...  0.852895  0.706136   \n",
      "4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.686228  0.373469   \n",
      "\n",
      "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0  0.654147   0.931818  0.705790  0.803206     0.948357     0.705790  \n",
      "1  0.752739   0.891057  0.857590  0.874003     0.895149     0.857590  \n",
      "2  0.771518   0.930192  0.834116  0.879538     0.937402     0.834116  \n",
      "3  0.705790   0.864297  0.837246  0.850556     0.868545     0.837246  \n",
      "4  0.372457   0.673469  0.723005  0.697358     0.649452     0.723005  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(xtrain, ytrain)\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "# total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 10),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 10, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate = 0.1,max_depth = 10,random_state = 50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50)]\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  # evaluate model\n",
    "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "  # model.fit(xtrain, ytrain)\n",
    "  # pred = model.predict(xtest)\n",
    "  pred = cross_val_predict(model, x_ros, y_ros, cv=cv, n_jobs=-1)\n",
    "\n",
    "  # cm1 = confusion_matrix(y, y_pred)\n",
    "  # report performance\n",
    "  Accuracy = accuracy_score(y_ros, pred)\n",
    "  mcc = matthews_corrcoef(y_ros, pred)\n",
    "  cm1 = confusion_matrix(y_ros, pred)\n",
    "  kappa = cohen_kappa_score(y_ros, pred)\n",
    "  f1 = f1_score(y_ros, pred)\n",
    "  precision_score = precision_score(y_ros, pred)\n",
    "  recall_score = recall_score(y_ros, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  # y_pred = np.argmax(y_pred, axis=0)\n",
    "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dfac1-9750-49e1-ba7d-d6e6fec10099",
   "metadata": {},
   "source": [
    "PCA_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1b6abf-bd24-4a94-acba-738cad69a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424, 929)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10bf86ed-22f0-478e-acac-b6142749ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1424, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88750d5a-a26f-47b0-86a4-e76433f05e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_pca_100, xtest_pca_100 , ytrain, ytest = train_test_split(x_pca , y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3116b29d-0031-43a9-b887-c409f335b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Classifier  Accuracy       mcc  \\\n",
      "0  RandomForestClassifier(max_depth=10, n_estimat...  0.833333  0.675411   \n",
      "1  XGBClassifier(base_score=None, booster=None, c...  0.843096  0.687011   \n",
      "2      LGBMClassifier(max_depth=10, random_state=50)  0.860530  0.722185   \n",
      "3  GradientBoostingClassifier(learning_rate=0.5, ...  0.806137  0.612466   \n",
      "4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.687587  0.375421   \n",
      "\n",
      "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0  0.666667   0.897010  0.753138  0.818802     0.913529     0.753138  \n",
      "1  0.686192   0.860704  0.818689  0.839171     0.867503     0.818689  \n",
      "2  0.721060   0.881832  0.832636  0.856528     0.888424     0.832636  \n",
      "3  0.612273   0.798639  0.818689  0.808540     0.793584     0.818689  \n",
      "4  0.375174   0.694645  0.669456  0.681818     0.705718     0.669456  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(xtrain_pca_100, ytrain)\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "# total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 10),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 10, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate = 0.1,max_depth = 10,random_state = 50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50)]\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  # evaluate model\n",
    "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "  # model.fit(xtrain, ytrain)\n",
    "  # pred = model.predict(xtest)\n",
    "  pred = cross_val_predict(model, x_ros, y_ros, cv=cv, n_jobs=-1)\n",
    "\n",
    "  # cm1 = confusion_matrix(y, y_pred)\n",
    "  # report performance\n",
    "  Accuracy = accuracy_score(y_ros, pred)\n",
    "  mcc = matthews_corrcoef(y_ros, pred)\n",
    "  cm1 = confusion_matrix(y_ros, pred)\n",
    "  kappa = cohen_kappa_score(y_ros, pred)\n",
    "  f1 = f1_score(y_ros, pred)\n",
    "  precision_score = precision_score(y_ros, pred)\n",
    "  recall_score = recall_score(y_ros, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  # y_pred = np.argmax(y_pred, axis=0)\n",
    "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94208f18-594b-456e-a153-dd12ff441d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86a809f7-1975-4fc1-8d23-b7773462ab38",
   "metadata": {},
   "source": [
    "PCA_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0aeaa65-af10-4b89-8414-5531d1ad9981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Classifier  Accuracy       mcc  \\\n",
      "0  RandomForestClassifier(max_depth=10, n_estimat...  0.792732  0.586153   \n",
      "1  XGBClassifier(base_score=None, booster=None, c...  0.786676  0.573352   \n",
      "2      LGBMClassifier(max_depth=10, random_state=50)  0.794751  0.589528   \n",
      "3  GradientBoostingClassifier(learning_rate=0.5, ...  0.769852  0.541593   \n",
      "4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.690444  0.382054   \n",
      "\n",
      "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0  0.585464   0.807638  0.768506  0.787586     0.816958     0.768506  \n",
      "1  0.573351   0.786290  0.787349  0.786819     0.786003     0.787349  \n",
      "2  0.589502   0.792000  0.799462  0.795713     0.790040     0.799462  \n",
      "3  0.539704   0.749068  0.811575  0.779070     0.728129     0.811575  \n",
      "4  0.380888   0.676654  0.729475  0.702073     0.651413     0.729475  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca.shape\n",
    "\n",
    "xtrain_pca_50, xtest_pca_50 , ytrain, ytest = train_test_split(x_pca , y, test_size=0.2)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(xtrain_pca_50, ytrain)\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "# total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 10),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 10, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate = 0.1,max_depth = 10,random_state = 50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50)]\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  # evaluate model\n",
    "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "  # model.fit(xtrain, ytrain)\n",
    "  # pred = model.predict(xtest)\n",
    "  pred = cross_val_predict(model, x_ros, y_ros, cv=cv, n_jobs=-1)\n",
    "\n",
    "  # cm1 = confusion_matrix(y, y_pred)\n",
    "  # report performance\n",
    "  Accuracy = accuracy_score(y_ros, pred)\n",
    "  mcc = matthews_corrcoef(y_ros, pred)\n",
    "  cm1 = confusion_matrix(y_ros, pred)\n",
    "  kappa = cohen_kappa_score(y_ros, pred)\n",
    "  f1 = f1_score(y_ros, pred)\n",
    "  precision_score = precision_score(y_ros, pred)\n",
    "  recall_score = recall_score(y_ros, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  # y_pred = np.argmax(y_pred, axis=0)\n",
    "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553f476-b2ed-4160-873e-1326f34ebea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1a712bc-2dff-4883-9624-bf3d24a404f7",
   "metadata": {},
   "source": [
    "PCA_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd8f4884-4585-40f4-82f1-fafdfb3f60ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Classifier  Accuracy       mcc  \\\n",
      "0  RandomForestClassifier(max_depth=10, n_estimat...  0.781507  0.563133   \n",
      "1  XGBClassifier(base_score=None, booster=None, c...  0.770548  0.541109   \n",
      "2      LGBMClassifier(max_depth=10, random_state=50)  0.766438  0.533021   \n",
      "3  GradientBoostingClassifier(learning_rate=0.5, ...  0.749315  0.501073   \n",
      "4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.632192  0.267055   \n",
      "\n",
      "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0  0.563014   0.787413  0.771233  0.779239     0.791781     0.771233  \n",
      "1  0.541096   0.768707  0.773973  0.771331     0.767123     0.773973  \n",
      "2  0.532877   0.760375  0.778082  0.769127     0.754795     0.778082  \n",
      "3  0.498630   0.726933  0.798630  0.761097     0.700000     0.798630  \n",
      "4  0.264384   0.615846  0.702740  0.656430     0.561644     0.702740  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca.shape\n",
    "\n",
    "xtrain_pca_200, xtest_pca_200 , ytrain, ytest = train_test_split(x_pca , y, test_size=0.2)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(xtrain_pca_200, ytrain)\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "# total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 10),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 10, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate = 0.1,max_depth = 10,random_state = 50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50)]\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  # evaluate model\n",
    "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "  # model.fit(xtrain, ytrain)\n",
    "  # pred = model.predict(xtest)\n",
    "  pred = cross_val_predict(model, x_ros, y_ros, cv=cv, n_jobs=-1)\n",
    "\n",
    "  # cm1 = confusion_matrix(y, y_pred)\n",
    "  # report performance\n",
    "  Accuracy = accuracy_score(y_ros, pred)\n",
    "  mcc = matthews_corrcoef(y_ros, pred)\n",
    "  cm1 = confusion_matrix(y_ros, pred)\n",
    "  kappa = cohen_kappa_score(y_ros, pred)\n",
    "  f1 = f1_score(y_ros, pred)\n",
    "  precision_score = precision_score(y_ros, pred)\n",
    "  recall_score = recall_score(y_ros, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  # y_pred = np.argmax(y_pred, axis=0)\n",
    "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181bad9-ec32-4ad1-9258-ac523b1fe3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2049d2b3-e0ed-4ae3-aa15-0e42077ad318",
   "metadata": {},
   "source": [
    "PCA_97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cccc73b-7294-4423-9482-ae8e4cda1036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Classifier  Accuracy       mcc  \\\n",
      "0  RandomForestClassifier(max_depth=10, n_estimat...  0.841128  0.692235   \n",
      "1  XGBClassifier(base_score=None, booster=None, c...  0.859010  0.720236   \n",
      "2      LGBMClassifier(max_depth=10, random_state=50)  0.870702  0.742418   \n",
      "3  GradientBoostingClassifier(learning_rate=0.5, ...  0.823934  0.648283   \n",
      "4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.678129  0.356260   \n",
      "\n",
      "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0  0.682256   0.910596  0.756534  0.826446     0.925722     0.756534  \n",
      "1  0.718019   0.889552  0.819807  0.853257     0.898212     0.819807  \n",
      "2  0.741403   0.891147  0.844567  0.867232     0.896836     0.844567  \n",
      "3  0.647868   0.812749  0.841816  0.827027     0.806052     0.841816  \n",
      "4  0.356259   0.678621  0.676754  0.677686     0.679505     0.676754  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.97)\n",
    "\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca.shape\n",
    "\n",
    "xtrain_pca_97p, xtest_pca_97p , ytrain, ytest = train_test_split(x_pca , y, test_size=0.2)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(xtrain_pca_97p, ytrain)\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "# total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 10),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 10, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate = 0.1,max_depth = 10,random_state = 50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50)]\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  # evaluate model\n",
    "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "  # model.fit(xtrain, ytrain)\n",
    "  # pred = model.predict(xtest)\n",
    "  pred = cross_val_predict(model, x_ros, y_ros, cv=cv, n_jobs=-1)\n",
    "\n",
    "  # cm1 = confusion_matrix(y, y_pred)\n",
    "  # report performance\n",
    "  Accuracy = accuracy_score(y_ros, pred)\n",
    "  mcc = matthews_corrcoef(y_ros, pred)\n",
    "  cm1 = confusion_matrix(y_ros, pred)\n",
    "  kappa = cohen_kappa_score(y_ros, pred)\n",
    "  f1 = f1_score(y_ros, pred)\n",
    "  precision_score = precision_score(y_ros, pred)\n",
    "  recall_score = recall_score(y_ros, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  # y_pred = np.argmax(y_pred, axis=0)\n",
    "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02fda3db-308d-4d52-8b7d-9a0f6a184ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139, 104)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_pca_97p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37355a62-6dac-46da-9b29-b14bbac6765b",
   "metadata": {},
   "source": [
    "PCA_98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b4ca00e-b739-4ed2-90a5-e5faac468680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Classifier  Accuracy       mcc  \\\n",
      "0  RandomForestClassifier(max_depth=10, n_estimat...  0.817227  0.652105   \n",
      "1  XGBClassifier(base_score=None, booster=None, c...  0.852241  0.707991   \n",
      "2      LGBMClassifier(max_depth=10, random_state=50)  0.860644  0.726212   \n",
      "3  GradientBoostingClassifier(learning_rate=0.5, ...  0.841036  0.682368   \n",
      "4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.703081  0.406475   \n",
      "\n",
      "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0  0.634454   0.912568  0.701681  0.793349     0.932773     0.701681  \n",
      "1  0.704482   0.891135  0.802521  0.844510     0.901961     0.802521  \n",
      "2  0.721289   0.908082  0.802521  0.852045     0.918768     0.802521  \n",
      "3  0.682073   0.851371  0.826331  0.838664     0.855742     0.826331  \n",
      "4  0.406162   0.711370  0.683473  0.697143     0.722689     0.683473  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.98)\n",
    "\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca.shape\n",
    "\n",
    "xtrain_pca_98p, xtest_pca_98p , ytrain, ytest = train_test_split(x_pca , y, test_size=0.2)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(xtrain_pca_98p, ytrain)\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "# total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 10),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 10, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate = 0.1,max_depth = 10,random_state = 50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50)]\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  # evaluate model\n",
    "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "  # model.fit(xtrain, ytrain)\n",
    "  # pred = model.predict(xtest)\n",
    "  pred = cross_val_predict(model, x_ros, y_ros, cv=cv, n_jobs=-1)\n",
    "\n",
    "  # cm1 = confusion_matrix(y, y_pred)\n",
    "  # report performance\n",
    "  Accuracy = accuracy_score(y_ros, pred)\n",
    "  mcc = matthews_corrcoef(y_ros, pred)\n",
    "  cm1 = confusion_matrix(y_ros, pred)\n",
    "  kappa = cohen_kappa_score(y_ros, pred)\n",
    "  f1 = f1_score(y_ros, pred)\n",
    "  precision_score = precision_score(y_ros, pred)\n",
    "  recall_score = recall_score(y_ros, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  # y_pred = np.argmax(y_pred, axis=0)\n",
    "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c36cd72-9a03-492d-b7fe-adfec9500f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139, 142)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_pca_98p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba106644-e1d3-4f46-8596-7d288d4a1547",
   "metadata": {},
   "source": [
    "PCA_99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3031d584-fcb0-4713-b1da-9434dee9e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Classifier  Accuracy       mcc  \\\n",
      "0  RandomForestClassifier(max_depth=10, n_estimat...  0.824061  0.668701   \n",
      "1  XGBClassifier(base_score=None, booster=None, c...  0.840056  0.683358   \n",
      "2      LGBMClassifier(max_depth=10, random_state=50)  0.853964  0.713795   \n",
      "3  GradientBoostingClassifier(learning_rate=0.5, ...  0.825452  0.651086   \n",
      "4  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.678720  0.357509   \n",
      "\n",
      "      Kappa  precision    recall        f1  sensitivity  specificity  \n",
      "0  0.648122   0.929889  0.700974  0.799366     0.947149     0.700974  \n",
      "1  0.680111   0.876733  0.791377  0.831871     0.888734     0.791377  \n",
      "2  0.707928   0.905901  0.789986  0.843982     0.917942     0.789986  \n",
      "3  0.650904   0.833333  0.813630  0.823364     0.837274     0.813630  \n",
      "4  0.357441   0.675307  0.688456  0.681818     0.668985     0.688456  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.99)\n",
    "\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca.shape\n",
    "\n",
    "xtrain_pca_99p, xtest_pca_99p , ytrain, ytest = train_test_split(x_pca , y, test_size=0.2)\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_ros, y_ros = ros.fit_resample(xtrain_pca_99p, ytrain)\n",
    "total_Metics = []\n",
    "total_Metics = pd.DataFrame(total_Metics)\n",
    "total_Metics['Classifier'] = 'Classifier'\n",
    "total_Metics['Accuracy'] = 'Accuracy'\n",
    "total_Metics['mcc'] = 'mcc'\n",
    "# total_Metics['auc'] = 'auc'\n",
    "total_Metics['Kappa'] = 'Kappa'\n",
    "total_Metics['precision'] = 'precision'\n",
    "total_Metics['recall'] = 'recall'\n",
    "total_Metics['f1'] = 'f1'\n",
    "total_Metics['sensitivity'] = 'sensitivity'\n",
    "total_Metics['specificity'] = 'specificity'\n",
    "\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 10),\n",
    "          XGBClassifier(n_estimators = 200,max_depth = 10, learning_rate = 0.1),\n",
    "          LGBMClassifier(learning_rate = 0.1,max_depth = 10,random_state = 50),\n",
    "          GradientBoostingClassifier(n_estimators = 200, learning_rate = 0.5, random_state = 50),\n",
    "          AdaBoostClassifier(n_estimators = 200, learning_rate = 0.1, random_state = 50)]\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "for model in models:\n",
    "  from sklearn.metrics import f1_score, precision_score, recall_score, log_loss, accuracy_score, matthews_corrcoef, roc_auc_score, cohen_kappa_score\n",
    "  # evaluate model\n",
    "  # scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "  # model.fit(xtrain, ytrain)\n",
    "  # pred = model.predict(xtest)\n",
    "  pred = cross_val_predict(model, x_ros, y_ros, cv=cv, n_jobs=-1)\n",
    "\n",
    "  # cm1 = confusion_matrix(y, y_pred)\n",
    "  # report performance\n",
    "  Accuracy = accuracy_score(y_ros, pred)\n",
    "  mcc = matthews_corrcoef(y_ros, pred)\n",
    "  cm1 = confusion_matrix(y_ros, pred)\n",
    "  kappa = cohen_kappa_score(y_ros, pred)\n",
    "  f1 = f1_score(y_ros, pred)\n",
    "  precision_score = precision_score(y_ros, pred)\n",
    "  recall_score = recall_score(y_ros, pred)\n",
    "  sensitivity = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "  specificity = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "  # y_pred = np.argmax(y_pred, axis=0)\n",
    "  # auc = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "  total_Metics.loc[len(total_Metics.index)] = [model,Accuracy, mcc, kappa, precision_score,recall_score, f1, sensitivity,specificity]\n",
    "\n",
    "print(total_Metics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8df36acb-cdbd-40ca-933b-a0f0f596559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139, 208)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_pca_99p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c536276d-aff5-4574-8113-cc370d358ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
